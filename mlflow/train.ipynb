{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">About Author</p>\n",
    "## - ***`Project:` Fruit Classification Multiclass Problem***\n",
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">Introduction</span>**\n",
    "### ***üëã Hello, everyone! My name is Mehak Iftikhar, and I'm delighted to introduce myself to you. I am a Junior Data Scientist passionate about leveraging data to derive meaningful insights and drive impactful decisions. With a keen interest in exploring the realms of data science, I actively engage in various projects and share my learnings through platforms like Kaggle.***\n",
    "\n",
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">About Me</span>**\n",
    "### ***üîç As a Junior Data Scientist, I immerse myself in the world of data, constantly seeking innovative ways to analyze, interpret, and visualize information to solve real-world problems. My journey in data science is fueled by a curiosity to unravel patterns, discover trends, and uncover hidden insights within complex datasets.***\n",
    "\n",
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">My Work</span>**\n",
    "### ***üìä I regularly upload my data analysis notebooks and projects on Kaggle, where I showcase my skills in data manipulation, exploratory data analysis (EDA), machine learning, and more. Through these notebooks, I aim to contribute to the data science community by sharing methodologies, code snippets, and insights gained from my projects.***\n",
    "\n",
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">Passion & Goals</span>**\n",
    "### ***üí° My passion for data science extends beyond technical skills. I am dedicated to continuous learning and improvement, staying updated with the latest advancements in the field. My ultimate goal is to harness the power of data to make a positive impact on society, whether it's through enhancing business strategies, addressing societal challenges, or driving innovation in various domains.***\n",
    "\n",
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">Let's Connect</span>**\n",
    "### ***ü§ù I am always open to collaboration, knowledge sharing, and networking opportunities. Feel free to connect with me on Kaggle or other professional platforms to discuss data science, share ideas, or explore potential collaborations.***\n",
    "\n",
    "\n",
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">Contact Info</span>**\n",
    "### ***Click on link below to contact/follow/correct me:***\n",
    "\n",
    "- ***Email:*** mehakkhan301007@gmail.com\n",
    "- [LinkedIn](https://www.linkedin.com/in/mehak-iftikhar/)\n",
    "- [Facebook](https://www.facebook.com/profile.php?id=61552023122774)\n",
    "- [Twitter](https://twitter.com/mehakkhan874)\n",
    "- [Github](https://github.com/mehakiftikhar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">About Dataset</p>\n",
    "\n",
    "### ***`Dataset link:`*** [Fruit classification(10 Class)](https://www.kaggle.com/datasets/karimabdulnabi/fruit-classification10-class/data)\n",
    "\n",
    "#### **<h1 align=\"left\"><span style=\"color:#690e11;\">Classes Of Dataset</span>**\n",
    "### ***`Apple`***\n",
    "### ***`Orange`***\n",
    "### ***`Avocado`***\n",
    "### ***`Kiwi`***\n",
    "### ***`Mango`***\n",
    "### ***`Pinenapple`***\n",
    "### ***`Strawberries`***\n",
    "### ***`Banana`***\n",
    "### ***`Cherry`***\n",
    "### ***`Watermelon`***\n",
    "\n",
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">SOURCES</span>**\n",
    "### ***This data contains a set of images of 10 kind of fruits , that can be used to make classification using deep learning , i scraped this data from Instagram and google.***\n",
    "\n",
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">COLLECTION METHODOLOGY</span>**\n",
    "### ***This data was collected by scraping my code in this rebo : https://github.com/karim-abdulnabi/CNN_model/tree/main/scraping_project class of data set : Apple Orange Avocado Kiwi Mango Pinenapple Strawberries Banana Cherry Watermelon i had collected 230 image for all kind from fruit for training and 110 for test***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<h1 align=\"center\"><span style=\"color:#690e11;\">Specifics</span>**\n",
    "### ***Model: MobileNetV2***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Import Libraries</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, AveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from keras.preprocessing.image import load_img\n",
    "import cv2\n",
    "# encode both columns label and variety\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# ignore warnings   \n",
    "import warnings\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***train_datagen:***\n",
    "\n",
    "### ***`rescale=1./255:` Normalizes pixel values in the training images between 0 and 1. This is a common preprocessing step for image data, as neural networks typically work better with normalized values.***\n",
    "### ***`rotation_range=40:` Applies random rotations to the training images within a range of -40¬∞ to 40¬∞ degrees. This helps the model become more robust to variations in object orientation.***\n",
    "### ***`width_shift_range=0.1, height_shift_range=0.1:` Randomly shifts the training images horizontally and vertically by up to 10% of their width and height, respectively. This simulates small changes in camera position or object placement.***\n",
    "### ***`horizontal_flip=True:` Randomly flips the training images horizontally. This helps the model learn to recognize objects regardless of their orientation.***\n",
    "### ***`validation_split=0.2:` Splits the training data into training (80%) and validation (20%) sets. The validation set is used to monitor model performance during training and avoid overfitting.***\n",
    "\n",
    "## ***test_datagen:***\n",
    "\n",
    "### ***`rescale=1./255:` Applies the same normalization to the test images as the training images. This ensures consistency in the data processing pipeline.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/18 14:38:51 INFO mlflow.tracking.fluent: Experiment with name 'Fruit_Classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Fruit_Classification\")\n",
    "\n",
    "rescale = 1./255\n",
    "rotation_range=40\n",
    "width_shift_range=0.1\n",
    "height_shift_range=0.1\n",
    "horizontal_flip=True\n",
    "validation_split=0.2\n",
    "\n",
    "mlflow.log_param(\"rescale\", rescale)\n",
    "mlflow.log_param(\"rotation_range\", rotation_range)\n",
    "mlflow.log_param(\"width_shift_range\", width_shift_range) \n",
    "mlflow.log_param(\"height_shift_range\", height_shift_range)\n",
    "mlflow.log_param(\"model_type\", \"MobileNetV2\")\n",
    "mlflow.log_param(\"validation_split\", validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = rescale, \n",
    "                             rotation_range=rotation_range,\n",
    "                             width_shift_range=width_shift_range,\n",
    "                             height_shift_range=height_shift_range,\n",
    "                             horizontal_flip=horizontal_flip,\n",
    "                             validation_split=validation_split)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = rescale,\n",
    "                                validation_split=validation_split)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = rescale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Load The Train Images And Test Images</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_datagen.flow_from_directory(\n",
    "    directory = 'data/train',\n",
    "    batch_size = 32,\n",
    "    target_size = (224, 224),\n",
    "    class_mode='categorical',\n",
    "    subset=\"training\",\n",
    "    seed=123  \n",
    ")\n",
    "\n",
    "validation_ds = val_datagen.flow_from_directory(\n",
    "    directory='data/train',\n",
    "    batch_size=32,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    subset=\"validation\",\n",
    "    seed=123 \n",
    ")\n",
    "\n",
    "\n",
    "test_ds = train_datagen.flow_from_directory(\n",
    "    directory = 'data/test',\n",
    "    batch_size = 32,\n",
    "    target_size = (224, 224),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Visualizing The Train Images</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(path, num_images=5):\n",
    "\n",
    "    # Get a list of image filenames\n",
    "    image_filenames = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "    if not image_filenames:\n",
    "        raise ValueError(\"No images found in the specified path\")\n",
    "\n",
    "    # Select random images\n",
    "    selected_images = random.sample(image_filenames, min(num_images, len(image_filenames)))\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3), facecolor='white')\n",
    "\n",
    "    # Display each image\n",
    "    for i, image_filename in enumerate(selected_images):\n",
    "        # Load image\n",
    "        image_path = os.path.join(path, image_filename)\n",
    "        image = plt.imread(image_path)\n",
    "\n",
    "        # Display image\n",
    "        axes[i].imshow(image)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(image_filename)  # Set image filename as title\n",
    "\n",
    "    # Adjust layout and display\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Model Building</p>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:left;color:#690e11;\">Transfer Learning</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained EfficientNetB4 model without the top classification layer\n",
    "MobileNetV2_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3),\n",
    "                              pooling='avg')\n",
    "\n",
    "# Freeze the pre-trained base model layers\n",
    "MobileNetV2_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the pre-trained Xception base\n",
    "model.add(MobileNetV2_base)\n",
    "\n",
    "# Batch Normalization\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.35))\n",
    "\n",
    "# Add a dense layer with 120 units and ReLU activation function\n",
    "model.add(Dense(220, activation='relu')) \n",
    "\n",
    "# Add a dense layer with 120 units and ReLU activation function\n",
    "model.add(Dense(60, activation='relu'))\n",
    "\n",
    "# Add the output layer with 1 unit and sigmoid activation function for binary classification\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Check The Summary Of Model</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Compile The Model</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    " loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Model Training</p>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# # Define the callback function\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "history= model.fit(train_ds,\n",
    "    validation_data=validation_ds,\n",
    "    steps_per_epoch=len(train_ds),\n",
    "    epochs=100, \n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer accuracy, loss et precision sur train et val\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "train_precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Plotting The Loss And Accuracy</p>**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# evaluate the model\n",
    "loss = model.evaluate(validation_ds)\n",
    "\n",
    "# Plotting the training and testing loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy of training and validation\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style=\"font-family:newtimeroman;font-size:150%;text-align:center;color:#690e11;\">Predictions</p>**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Get the class labels\n",
    "class_labels = list(test_ds.class_indices.keys())\n",
    "\n",
    "# Predict on each image and plot results\n",
    "num_images = 20\n",
    "num_images_per_row = 5  # Set the number of images per row\n",
    "num_rows = 4\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(num_images):\n",
    "    image, label = next(test_ds)\n",
    "    predictions = model.predict(image)\n",
    "    \n",
    "    # Iterate over each image in the batch\n",
    "    for j in range(len(image)):\n",
    "        if i * len(image) + j < num_images:  # Check if the total number of images exceeds the desired count\n",
    "            predicted_class = class_labels[np.argmax(predictions[j])]\n",
    "            true_class = class_labels[np.argmax(label[j])]\n",
    "            \n",
    "            plt.subplot(num_rows, num_images_per_row, i * len(image) + j + 1)\n",
    "            plt.imshow(image[j])\n",
    "            plt.title(f'True: {true_class}\\nPredicted: {predicted_class}')\n",
    "            plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **<p style=\"font-family:newtimeroman;font-size:200%;text-align:center;color:#690e11;\">THE END</p>**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2529046,
     "sourceId": 4292212,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
